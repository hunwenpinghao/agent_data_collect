# Qwen æ¨¡å‹è¯„ä¼°è„šæœ¬ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

`run_eval.sh` æ˜¯ä¸€ä¸ªå…¨åŠŸèƒ½çš„ Qwen æ¨¡å‹è¯„ä¼°è„šæœ¬ï¼Œæ”¯æŒç”Ÿæˆä»»åŠ¡çš„è‡ªåŠ¨è¯„ä¼°ï¼ŒåŒ…å«å¤šç§è¯„ä¼°æŒ‡æ ‡å’Œçµæ´»çš„é…ç½®é€‰é¡¹ã€‚

## åŠŸèƒ½ç‰¹ç‚¹

- ğŸš€ **ä¸€é”®è¯„ä¼°**: ç®€å•å‘½ä»¤å³å¯å®Œæˆæ¨¡å‹è¯„ä¼°
- ğŸ“Š **å¤šç§æŒ‡æ ‡**: æ”¯æŒ BLEUã€ROUGEã€ç²¾ç¡®åŒ¹é…ç­‰è¯„ä¼°æŒ‡æ ‡
- ğŸ”§ **è‡ªåŠ¨ä¿®å¤**: å†…ç½® transformers å…¼å®¹æ€§ä¿®å¤
- ğŸ’¾ **ç»“æœä¿å­˜**: è‡ªåŠ¨ä¿å­˜è¯„ä¼°ç»“æœå’Œé¢„æµ‹è¯¦æƒ…
- ğŸ¯ **çµæ´»é…ç½®**: æ”¯æŒå¤šç§å‚æ•°è‡ªå®šä¹‰
- ğŸ“± **å‹å¥½ç•Œé¢**: å½©è‰²è¾“å‡ºå’Œè¯¦ç»†è¿›åº¦æ˜¾ç¤º

## å¿«é€Ÿå¼€å§‹

### 1. åŸºæœ¬ç”¨æ³•

```bash
# ä½¿ç”¨é»˜è®¤è®¾ç½®è¯„ä¼°æ¨¡å‹
./run_eval.sh -m ./output/checkpoint-best -d ./data/test.jsonl

# æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯
./run_eval.sh --help
```

### 2. å®Œæ•´ç¤ºä¾‹

```bash
# å®Œæ•´é…ç½®çš„è¯„ä¼°
./run_eval.sh \
  --model-path ./output/checkpoint-1000 \
  --data-path ./data/test_sample.jsonl \
  --output-dir ./eval_results_v1 \
  --batch-size 4 \
  --max-tokens 512 \
  --temperature 0.7 \
  --metrics bleu,rouge,exact_match \
  --save-predictions \
  --verbose
```

### 3. ä½¿ç”¨æµ‹è¯•æ•°æ®

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç¤ºä¾‹æµ‹è¯•æ–‡ä»¶ï¼š

```bash
# ä½¿ç”¨å†…ç½®æµ‹è¯•æ•°æ®
./run_eval.sh -m ./output/checkpoint-best -d ./data/test_sample.jsonl
```

## å‚æ•°è¯´æ˜

| å‚æ•° | ç®€å†™ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--model-path` | `-m` | `./output/checkpoint-best` | å¾®è°ƒåçš„æ¨¡å‹è·¯å¾„ |
| `--data-path` | `-d` | `./data/test.jsonl` | è¯„ä¼°æ•°æ®æ–‡ä»¶è·¯å¾„ |
| `--output-dir` | `-o` | `./eval_results` | è¯„ä¼°ç»“æœè¾“å‡ºç›®å½• |
| `--batch-size` | `-b` | `4` | æ‰¹å¤„ç†å¤§å° |
| `--max-tokens` | `-t` | `512` | æœ€å¤§ç”Ÿæˆtokenæ•° |
| `--temperature` | - | `0.7` | ç”Ÿæˆæ¸©åº¦ï¼ˆ0-1ï¼‰ |
| `--top-p` | - | `0.9` | Top-pé‡‡æ ·å€¼ |
| `--device` | - | `auto` | è®¡ç®—è®¾å¤‡ï¼šcpu/cuda/auto |
| `--metrics` | - | `bleu,rouge` | è¯„ä¼°æŒ‡æ ‡åˆ—è¡¨ |
| `--save-predictions` | - | `false` | æ˜¯å¦ä¿å­˜é¢„æµ‹ç»“æœ |
| `--verbose` | - | `false` | æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡º |

## æ•°æ®æ ¼å¼

è¯„ä¼°æ•°æ®æ–‡ä»¶åº”ä¸º JSONL æ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰ï¼Œæ”¯æŒä»¥ä¸‹å­—æ®µï¼š

### æ ¼å¼1ï¼šæŒ‡ä»¤-è¾“å…¥-è¾“å‡º
```json
{
  "instruction": "è¯·è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½",
  "input": "",
  "output": "äººå·¥æ™ºèƒ½(AI)æ˜¯æŒ‡ç”±æœºå™¨å±•ç°å‡ºçš„æ™ºèƒ½..."
}
```

### æ ¼å¼2ï¼šé—®é¢˜-ç­”æ¡ˆ
```json
{
  "question": "Pythonä¸­å¦‚ä½•å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Ÿ",
  "answer": "åœ¨Pythonä¸­ï¼Œä½¿ç”¨defå…³é”®å­—æ¥å®šä¹‰å‡½æ•°..."
}
```

### æ ¼å¼3ï¼šæç¤º-å›å¤
```json
{
  "prompt": "è¯·å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„çŸ­è¯—",
  "response": "æ˜¥é£è½»æ‹‚æŸ³ä¸é•¿..."
}
```

## è¯„ä¼°æŒ‡æ ‡

### æ”¯æŒçš„æŒ‡æ ‡

- **BLEU**: åŸºäºn-gramçš„æ–‡æœ¬ç›¸ä¼¼åº¦æŒ‡æ ‡
- **ROUGE-1/2/L**: åŸºäºé‡å ç»Ÿè®¡çš„æ–‡æœ¬æ‘˜è¦è¯„ä¼°æŒ‡æ ‡
- **ç²¾ç¡®åŒ¹é…**: é¢„æµ‹ä¸å‚è€ƒç­”æ¡ˆå®Œå…¨åŒ¹é…çš„æ¯”ä¾‹

### æŒ‡æ ‡é…ç½®ç¤ºä¾‹

```bash
# åªä½¿ç”¨BLEU
./run_eval.sh -m model_path -d data_path --metrics bleu

# ä½¿ç”¨æ‰€æœ‰æŒ‡æ ‡
./run_eval.sh -m model_path -d data_path --metrics bleu,rouge,exact_match
```

## è¾“å‡ºç»“æœ

### æ§åˆ¶å°è¾“å‡ºç¤ºä¾‹

```
============================== Qwen æ¨¡å‹è¯„ä¼°è„šæœ¬ ==============================

ğŸ“ æ¨¡å‹è·¯å¾„: ./output/checkpoint-best
ğŸ“„ æ•°æ®è·¯å¾„: ./data/test_sample.jsonl
ğŸ“‚ è¾“å‡ºç›®å½•: ./eval_results
ğŸ”¢ æ‰¹å¤„ç†å¤§å°: 4
ğŸ¯ æœ€å¤§tokenæ•°: 512
ğŸŒ¡ï¸  ç”Ÿæˆæ¸©åº¦: 0.7
ğŸ“Š è¯„ä¼°æŒ‡æ ‡: bleu,rouge,exact_match
ğŸ’» è®¡ç®—è®¾å¤‡: auto

============================================================
æ¨¡å‹è¯„ä¼°ç»“æœ
============================================================
æ¨¡å‹è·¯å¾„: ./output/checkpoint-best
æ•°æ®è·¯å¾„: ./data/test_sample.jsonl
æ€»æ ·æœ¬æ•°: 10
æœ‰æ•ˆæ ·æœ¬æ•°: 10
æ—¶é—´æˆ³: 2024-01-15 14:30:25

è¯„ä¼°æŒ‡æ ‡:
  BLEU: 0.3456
  ROUGE-1: 0.4532
  ROUGE-L: 0.4012
  EXACT_MATCH: 0.2000

ç»Ÿè®¡ä¿¡æ¯:
  å¹³å‡é¢„æµ‹é•¿åº¦: 25.3 tokens
  å¹³å‡å‚è€ƒé•¿åº¦: 28.7 tokens

ç»“æœæ–‡ä»¶: ./eval_results/evaluation_results.json
é¢„æµ‹æ–‡ä»¶: ./eval_results/predictions.jsonl
============================================================
```

### è¾“å‡ºæ–‡ä»¶

1. **evaluation_results.json**: å®Œæ•´çš„è¯„ä¼°ç»“æœï¼ŒåŒ…å«æŒ‡æ ‡å’Œé…ç½®ä¿¡æ¯
2. **predictions.jsonl**: è¯¦ç»†çš„é¢„æµ‹ç»“æœï¼ˆå¦‚æœå¯ç”¨ `--save-predictions`ï¼‰
3. **eval_model.py**: è‡ªåŠ¨ç”Ÿæˆçš„Pythonè¯„ä¼°è„šæœ¬

## é«˜çº§ç”¨æ³•

### 1. å¯¹æ¯”ä¸åŒæ¨¡å‹

```bash
# è¯„ä¼°åŸºç¡€æ¨¡å‹
./run_eval.sh -m Qwen/Qwen2.5-7B-Instruct -d ./data/test.jsonl -o ./eval_base

# è¯„ä¼°å¾®è°ƒæ¨¡å‹
./run_eval.sh -m ./output/checkpoint-best -d ./data/test.jsonl -o ./eval_tuned

# æ¯”è¾ƒç»“æœ
python -c "
import json
with open('./eval_base/evaluation_results.json') as f: base = json.load(f)
with open('./eval_tuned/evaluation_results.json') as f: tuned = json.load(f)
print('åŸºç¡€æ¨¡å‹ BLEU:', base['metrics']['bleu'])
print('å¾®è°ƒæ¨¡å‹ BLEU:', tuned['metrics']['bleu'])
print('æ”¹è¿›å¹…åº¦:', tuned['metrics']['bleu'] - base['metrics']['bleu'])
"
```

### 2. æ‰¹é‡è¯„ä¼°

```bash
# è¯„ä¼°å¤šä¸ªæ£€æŸ¥ç‚¹
for checkpoint in ./output/checkpoint-*; do
  if [ -d "$checkpoint" ]; then
    echo "è¯„ä¼°: $checkpoint"
    ./run_eval.sh -m "$checkpoint" -d ./data/test.jsonl -o "./eval_results/$(basename $checkpoint)"
  fi
done
```

### 3. ä¸åŒç”Ÿæˆå‚æ•°æµ‹è¯•

```bash
# æµ‹è¯•ä¸åŒæ¸©åº¦
for temp in 0.1 0.5 0.7 0.9; do
  ./run_eval.sh -m ./output/checkpoint-best -d ./data/test.jsonl \
    --temperature $temp -o "./eval_temp_$temp"
done
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ¨¡å‹åŠ è½½å¤±è´¥**
   - æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®
   - ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†…å­˜/æ˜¾å­˜
   - æŸ¥çœ‹æ˜¯å¦éœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶

2. **ä¾èµ–åŒ…ç¼ºå¤±**
   ```bash
   pip install torch transformers datasets pandas tqdm
   pip install rouge nltk  # å¯é€‰ï¼šç”¨äºæ›´å‡†ç¡®çš„æŒ‡æ ‡è®¡ç®—
   ```

3. **CUDAç›¸å…³é”™è¯¯**
   ```bash
   # å¼ºåˆ¶ä½¿ç”¨CPU
   ./run_eval.sh -m model_path -d data_path --device cpu
   ```

4. **å†…å­˜ä¸è¶³**
   ```bash
   # å‡å°æ‰¹å¤„ç†å¤§å°
   ./run_eval.sh -m model_path -d data_path --batch-size 1
   ```

### è°ƒè¯•æ¨¡å¼

```bash
# å¯ç”¨è¯¦ç»†è¾“å‡º
./run_eval.sh -m model_path -d data_path --verbose

# ä¿å­˜é¢„æµ‹ç»“æœç”¨äºåˆ†æ
./run_eval.sh -m model_path -d data_path --save-predictions
```

## æ³¨æ„äº‹é¡¹

1. **æ•°æ®æ ¼å¼**: ç¡®ä¿è¯„ä¼°æ•°æ®ä¸ºæœ‰æ•ˆçš„JSONLæ ¼å¼
2. **æ¨¡å‹å…¼å®¹æ€§**: è„šæœ¬å†…ç½®äº†Qwenæ¨¡å‹çš„å…¼å®¹æ€§ä¿®å¤
3. **è®¡ç®—èµ„æº**: æ ¹æ®æ¨¡å‹å¤§å°å’Œæ•°æ®é‡è°ƒæ•´æ‰¹å¤„ç†å¤§å°
4. **è¯„ä¼°å…¬å¹³æ€§**: ä½¿ç”¨ç›¸åŒçš„æ•°æ®å’Œå‚æ•°å¯¹æ¯”ä¸åŒæ¨¡å‹

## ç¤ºä¾‹ç»“æœåˆ†æ

è¯„ä¼°å®Œæˆåï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹è„šæœ¬åˆ†æç»“æœï¼š

```python
import json
import pandas as pd

# è¯»å–è¯„ä¼°ç»“æœ
with open('./eval_results/evaluation_results.json', 'r') as f:
    results = json.load(f)

print("è¯„ä¼°æ‘˜è¦:")
print(f"æ¨¡å‹: {results['model_path']}")
print(f"æ ·æœ¬æ•°: {results['num_samples']}")
print("\næŒ‡æ ‡è¯¦æƒ…:")
for metric, score in results['metrics'].items():
    if not metric.startswith('num_') and not metric.startswith('avg_'):
        print(f"  {metric}: {score:.4f}")

# åˆ†æé¢„æµ‹ç»“æœï¼ˆå¦‚æœä¿å­˜äº†ï¼‰
try:
    predictions = []
    with open('./eval_results/predictions.jsonl', 'r') as f:
        for line in f:
            predictions.append(json.loads(line))
    
    df = pd.DataFrame(predictions)
    print(f"\né¢„æµ‹ç»Ÿè®¡:")
    print(f"å¹³å‡é¢„æµ‹é•¿åº¦: {df['prediction'].str.len().mean():.1f} å­—ç¬¦")
    print(f"å¹³å‡å‚è€ƒé•¿åº¦: {df['reference'].str.len().mean():.1f} å­—ç¬¦")
    
except FileNotFoundError:
    print("æœªæ‰¾åˆ°è¯¦ç»†é¢„æµ‹æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ --save-predictions é€‰é¡¹")
```

---

## è”ç³»æ”¯æŒ

å¦‚æœé‡åˆ°é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·ï¼š

1. æ£€æŸ¥é”™è¯¯æ—¥å¿—
2. æŸ¥çœ‹ç”Ÿæˆçš„Pythonè„šæœ¬ `eval_model.py`
3. ä½¿ç”¨ `--verbose` é€‰é¡¹è·å–è¯¦ç»†ä¿¡æ¯
4. ç¡®ä¿æ‰€æœ‰ä¾èµ–éƒ½å·²æ­£ç¡®å®‰è£…

ç¥ä½ è¯„ä¼°é¡ºåˆ©ï¼ğŸ‰ 
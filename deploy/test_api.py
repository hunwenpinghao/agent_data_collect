#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
APIæœåŠ¡æµ‹è¯•è„šæœ¬
ç”¨äºæµ‹è¯•éƒ¨ç½²åçš„APIæœåŠ¡åŠŸèƒ½å’Œæ€§èƒ½
"""

import requests
import json
import time
import asyncio
import concurrent.futures
import argparse
from typing import List, Dict
import statistics

class APITester:
    def __init__(self, base_url: str, api_key: str = None):
        self.base_url = base_url.rstrip('/')
        self.headers = {"Content-Type": "application/json"}
        if api_key:
            self.headers["Authorization"] = f"Bearer {api_key}"
    
    def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        try:
            response = requests.get(f"{self.base_url}/health", headers=self.headers, timeout=10)
            if response.status_code == 200:
                result = response.json()
                print(f"âœ… å¥åº·æ£€æŸ¥é€šè¿‡: {result}")
                return True
            else:
                print(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ å¥åº·æ£€æŸ¥å¼‚å¸¸: {e}")
            return False
    
    def get_model_info(self) -> Dict:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        try:
            response = requests.get(f"{self.base_url}/model/info", headers=self.headers, timeout=10)
            if response.status_code == 200:
                result = response.json()
                print(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯: {json.dumps(result, indent=2, ensure_ascii=False)}")
                return result
            else:
                print(f"âŒ è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: {response.status_code}")
                return {}
        except Exception as e:
            print(f"âŒ è·å–æ¨¡å‹ä¿¡æ¯å¼‚å¸¸: {e}")
            return {}
    
    def single_inference(self, prompt: str, **kwargs) -> Dict:
        """å•æ¬¡æ¨ç†æµ‹è¯•"""
        payload = {
            "prompt": prompt,
            "max_length": kwargs.get("max_length", 512),
            "temperature": kwargs.get("temperature", 0.7),
            "top_p": kwargs.get("top_p", 0.9)
        }
        
        start_time = time.time()
        try:
            response = requests.post(
                f"{self.base_url}/generate", 
                headers=self.headers, 
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                elapsed_time = time.time() - start_time
                
                print(f"ğŸ¤– è¾“å…¥: {prompt}")
                print(f"ğŸ“ è¾“å‡º: {result['response']}")
                print(f"â±ï¸  æ¨ç†æ—¶é—´: {result['inference_time']:.2f}s")
                print(f"ğŸ”„ æ€»æ—¶é—´: {elapsed_time:.2f}s")
                print("-" * 50)
                
                return {
                    "success": True,
                    "response": result["response"],
                    "inference_time": result["inference_time"],
                    "total_time": elapsed_time
                }
            else:
                print(f"âŒ æ¨ç†å¤±è´¥: {response.status_code} - {response.text}")
                return {"success": False, "error": response.text}
                
        except Exception as e:
            elapsed_time = time.time() - start_time
            print(f"âŒ æ¨ç†å¼‚å¸¸: {e}, è€—æ—¶: {elapsed_time:.2f}s")
            return {"success": False, "error": str(e), "total_time": elapsed_time}
    
    def batch_inference_test(self, prompts: List[str], concurrent: int = 5) -> Dict:
        """æ‰¹é‡æ¨ç†æ€§èƒ½æµ‹è¯•"""
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡æ¨ç†æµ‹è¯•ï¼Œå¹¶å‘æ•°: {concurrent}")
        print(f"ğŸ“ æµ‹è¯•æ ·æœ¬æ•°: {len(prompts)}")
        
        results = []
        start_time = time.time()
        
        def single_request(prompt):
            return self.single_inference(prompt)
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent) as executor:
            future_to_prompt = {executor.submit(single_request, prompt): prompt for prompt in prompts}
            
            for future in concurrent.futures.as_completed(future_to_prompt):
                result = future.result()
                results.append(result)
        
        total_time = time.time() - start_time
        
        # ç»Ÿè®¡ç»“æœ
        successful_results = [r for r in results if r.get("success", False)]
        failed_results = [r for r in results if not r.get("success", True)]
        
        if successful_results:
            inference_times = [r["inference_time"] for r in successful_results]
            total_times = [r["total_time"] for r in successful_results]
            
            stats = {
                "total_requests": len(prompts),
                "successful_requests": len(successful_results),
                "failed_requests": len(failed_results),
                "success_rate": len(successful_results) / len(prompts) * 100,
                "total_time": total_time,
                "average_inference_time": statistics.mean(inference_times),
                "median_inference_time": statistics.median(inference_times),
                "p95_inference_time": statistics.quantiles(inference_times, n=20)[18] if len(inference_times) > 1 else inference_times[0],
                "average_total_time": statistics.mean(total_times),
                "throughput": len(successful_results) / total_time
            }
        else:
            stats = {
                "total_requests": len(prompts),
                "successful_requests": 0,
                "failed_requests": len(failed_results),
                "success_rate": 0,
                "total_time": total_time
            }
        
        print("\nğŸ“Š æ‰¹é‡æµ‹è¯•ç»Ÿè®¡:")
        for key, value in stats.items():
            print(f"  {key}: {value}")
        
        return stats
    
    def stress_test(self, prompt: str, duration: int = 60, concurrent: int = 10) -> Dict:
        """å‹åŠ›æµ‹è¯•"""
        print(f"ğŸ’ª å¼€å§‹å‹åŠ›æµ‹è¯•")
        print(f"â±ï¸  æµ‹è¯•æ—¶é•¿: {duration}ç§’")
        print(f"ğŸ”„ å¹¶å‘æ•°: {concurrent}")
        print(f"ğŸ“ æµ‹è¯•prompt: {prompt}")
        
        results = []
        start_time = time.time()
        end_time = start_time + duration
        
        def worker():
            worker_results = []
            while time.time() < end_time:
                result = self.single_inference(prompt)
                worker_results.append(result)
            return worker_results
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent) as executor:
            futures = [executor.submit(worker) for _ in range(concurrent)]
            
            for future in concurrent.futures.as_completed(futures):
                worker_results = future.result()
                results.extend(worker_results)
        
        actual_duration = time.time() - start_time
        
        # ç»Ÿè®¡ç»“æœ
        successful_results = [r for r in results if r.get("success", False)]
        failed_results = [r for r in results if not r.get("success", True)]
        
        if successful_results:
            inference_times = [r["inference_time"] for r in successful_results]
            
            stats = {
                "duration": actual_duration,
                "total_requests": len(results),
                "successful_requests": len(successful_results),
                "failed_requests": len(failed_results),
                "success_rate": len(successful_results) / len(results) * 100,
                "average_inference_time": statistics.mean(inference_times),
                "p95_inference_time": statistics.quantiles(inference_times, n=20)[18] if len(inference_times) > 1 else inference_times[0],
                "qps": len(successful_results) / actual_duration
            }
        else:
            stats = {
                "duration": actual_duration,
                "total_requests": len(results),
                "successful_requests": 0,
                "failed_requests": len(failed_results),
                "success_rate": 0,
                "qps": 0
            }
        
        print("\nğŸ’ª å‹åŠ›æµ‹è¯•ç»Ÿè®¡:")
        for key, value in stats.items():
            print(f"  {key}: {value}")
        
        return stats

def main():
    parser = argparse.ArgumentParser(description="APIæœåŠ¡æµ‹è¯•å·¥å…·")
    parser.add_argument("--url", type=str, required=True, help="APIæœåŠ¡åœ°å€")
    parser.add_argument("--api_key", type=str, help="APIå¯†é’¥")
    parser.add_argument("--test_type", type=str, default="all", 
                       choices=["health", "single", "batch", "stress", "all"],
                       help="æµ‹è¯•ç±»å‹")
    parser.add_argument("--concurrent", type=int, default=5, help="å¹¶å‘æ•°")
    parser.add_argument("--duration", type=int, default=60, help="å‹åŠ›æµ‹è¯•æŒç»­æ—¶é—´(ç§’)")
    
    args = parser.parse_args()
    
    tester = APITester(args.url, args.api_key)
    
    # æµ‹è¯•æ ·æœ¬
    test_prompts = [
        "è¯·ä¸ºä¸€å®¶å’–å•¡åº—å†™ä¸€æ®µå°çº¢ä¹¦é£æ ¼çš„æ–‡æ¡ˆ",
        "å¦‚ä½•åˆ¶ä½œä¸€æ¯å¥½å–çš„æ‹¿é“å’–å•¡ï¼Ÿ",
        "æ¨èå‡ å®¶ä¸Šæµ·çš„ç½‘çº¢å’–å•¡åº—",
        "ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†å²",
        "å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—",
        "è§£é‡Šä¸€ä¸‹æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„åŒºåˆ«",
        "æ¨èä¸€äº›é€‚åˆæ–°æ‰‹çš„ç¼–ç¨‹ä¹¦ç±",
        "ä»‹ç»ä¸€ä¸‹ç«å±±å¼•æ“çš„ä¸»è¦æœåŠ¡",
        "å¦‚ä½•åšå¥½æ—¶é—´ç®¡ç†ï¼Ÿ",
        "åˆ†æä¸€ä¸‹å½“å‰AIè¡Œä¸šçš„å‘å±•è¶‹åŠ¿"
    ]
    
    print("ğŸ§ª å¼€å§‹APIæœåŠ¡æµ‹è¯•")
    print("=" * 50)
    
    try:
        # å¥åº·æ£€æŸ¥
        if args.test_type in ["health", "all"]:
            print("\n1. å¥åº·æ£€æŸ¥æµ‹è¯•")
            if not tester.health_check():
                print("âŒ å¥åº·æ£€æŸ¥å¤±è´¥ï¼Œç»ˆæ­¢æµ‹è¯•")
                return
        
        # æ¨¡å‹ä¿¡æ¯
        if args.test_type in ["single", "batch", "stress", "all"]:
            print("\n2. æ¨¡å‹ä¿¡æ¯æµ‹è¯•")
            tester.get_model_info()
        
        # å•æ¬¡æ¨ç†æµ‹è¯•
        if args.test_type in ["single", "all"]:
            print("\n3. å•æ¬¡æ¨ç†æµ‹è¯•")
            tester.single_inference(test_prompts[0])
        
        # æ‰¹é‡æ¨ç†æµ‹è¯•
        if args.test_type in ["batch", "all"]:
            print("\n4. æ‰¹é‡æ¨ç†æµ‹è¯•")
            tester.batch_inference_test(test_prompts[:5], concurrent=args.concurrent)
        
        # å‹åŠ›æµ‹è¯•
        if args.test_type in ["stress", "all"]:
            print("\n5. å‹åŠ›æµ‹è¯•")
            tester.stress_test(test_prompts[0], duration=args.duration, concurrent=args.concurrent)
        
        print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")

if __name__ == "__main__":
    main() 
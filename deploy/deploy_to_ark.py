#!/usr/bin/env python3
"""
ä½¿ç”¨ç«å±±æ–¹èˆŸAPIéƒ¨ç½²æ¨¡å‹
"""

import requests
import json
import time
import os
import argparse

class VolcanoArkClient:
    def __init__(self, api_key, api_secret, endpoint):
        self.api_key = api_key
        self.api_secret = api_secret
        self.endpoint = endpoint
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    def upload_model(self, model_path, model_name):
        """ä¸Šä¼ æ¨¡å‹åˆ°ç«å±±æ–¹èˆŸ"""
        print(f"ä¸Šä¼ æ¨¡å‹: {model_name}")
        
        # å‹ç¼©æ¨¡å‹æ–‡ä»¶
        import tarfile
        with tarfile.open(f"{model_name}.tar.gz", "w:gz") as tar:
            tar.add(model_path, arcname=model_name)
        
        # ä¸Šä¼ åˆ°å¯¹è±¡å­˜å‚¨
        # è¿™é‡Œéœ€è¦æ ¹æ®ç«å±±å¼•æ“çš„å…·ä½“APIè°ƒæ•´
        upload_url = f"{self.endpoint}/models/upload"
        
        with open(f"{model_name}.tar.gz", "rb") as f:
            files = {"model": f}
            data = {"name": model_name, "version": "1.0.0"}
            
            response = requests.post(
                upload_url,
                headers={"Authorization": f"Bearer {self.api_key}"},
                data=data,
                files=files
            )
        
        if response.status_code == 200:
            model_id = response.json()["model_id"]
            print(f"âœ… æ¨¡å‹ä¸Šä¼ æˆåŠŸï¼ŒID: {model_id}")
            return model_id
        else:
            raise Exception(f"æ¨¡å‹ä¸Šä¼ å¤±è´¥: {response.text}")
    
    def create_endpoint(self, model_id, endpoint_name, instance_type="ml.g4dn.xlarge"):
        """åˆ›å»ºæ¨ç†ç«¯ç‚¹"""
        print(f"åˆ›å»ºæ¨ç†ç«¯ç‚¹: {endpoint_name}")
        
        endpoint_config = {
            "name": endpoint_name,
            "model_id": model_id,
            "instance_type": instance_type,
            "initial_instance_count": 1,
            "auto_scaling": {
                "enabled": True,
                "min_capacity": 1,
                "max_capacity": 10,
                "target_value": 70
            },
            "environment": {
                "MAX_BATCH_SIZE": "32",
                "MAX_SEQUENCE_LENGTH": "2048"
            }
        }
        
        response = requests.post(
            f"{self.endpoint}/endpoints",
            headers=self.headers,
            json=endpoint_config
        )
        
        if response.status_code == 201:
            endpoint_info = response.json()
            print(f"âœ… ç«¯ç‚¹åˆ›å»ºæˆåŠŸ: {endpoint_info['endpoint_url']}")
            return endpoint_info
        else:
            raise Exception(f"ç«¯ç‚¹åˆ›å»ºå¤±è´¥: {response.text}")
    
    def wait_for_endpoint(self, endpoint_id, timeout=1800):
        """ç­‰å¾…ç«¯ç‚¹å°±ç»ª"""
        print("ç­‰å¾…ç«¯ç‚¹éƒ¨ç½²å®Œæˆ...")
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            response = requests.get(
                f"{self.endpoint}/endpoints/{endpoint_id}",
                headers=self.headers
            )
            
            if response.status_code == 200:
                status = response.json()["status"]
                print(f"ç«¯ç‚¹çŠ¶æ€: {status}")
                
                if status == "InService":
                    print("âœ… ç«¯ç‚¹å·²å°±ç»ª")
                    return True
                elif status == "Failed":
                    raise Exception("ç«¯ç‚¹éƒ¨ç½²å¤±è´¥")
            
            time.sleep(30)
        
        raise Exception("ç«¯ç‚¹éƒ¨ç½²è¶…æ—¶")
    
    def test_endpoint(self, endpoint_url, test_prompt="ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±"):
        """æµ‹è¯•ç«¯ç‚¹"""
        print(f"æµ‹è¯•ç«¯ç‚¹: {test_prompt}")
        
        payload = {
            "prompt": test_prompt,
            "max_length": 512,
            "temperature": 0.7,
            "top_p": 0.9
        }
        
        response = requests.post(
            f"{endpoint_url}/generate",
            headers=self.headers,
            json=payload
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… æµ‹è¯•æˆåŠŸ: {result['response']}")
            return result
        else:
            raise Exception(f"æµ‹è¯•å¤±è´¥: {response.text}")

def main():
    parser = argparse.ArgumentParser(description="éƒ¨ç½²æ¨¡å‹åˆ°ç«å±±æ–¹èˆŸ")
    parser.add_argument("--model_path", type=str, required=True, help="æ¨¡å‹è·¯å¾„")
    parser.add_argument("--model_name", type=str, required=True, help="æ¨¡å‹åç§°")
    parser.add_argument("--endpoint_name", type=str, required=True, help="ç«¯ç‚¹åç§°")
    parser.add_argument("--instance_type", type=str, default="ml.g4dn.2xlarge", help="å®ä¾‹ç±»å‹")
    
    args = parser.parse_args()
    
    # é…ç½®ä¿¡æ¯
    api_key = os.getenv("VOLCANO_API_KEY")
    api_secret = os.getenv("VOLCANO_API_SECRET")
    endpoint = os.getenv("VOLCANO_ENDPOINT", "https://ark.volcengine.com/api/v1")
    
    if not api_key or not api_secret:
        print("âŒ è¯·è®¾ç½®ç¯å¢ƒå˜é‡ VOLCANO_API_KEY å’Œ VOLCANO_API_SECRET")
        return
    
    client = VolcanoArkClient(api_key, api_secret, endpoint)
    
    try:
        # 1. ä¸Šä¼ æ¨¡å‹
        model_id = client.upload_model(args.model_path, args.model_name)
        
        # 2. åˆ›å»ºç«¯ç‚¹
        endpoint_info = client.create_endpoint(
            model_id, 
            args.endpoint_name,
            args.instance_type
        )
        
        # 3. ç­‰å¾…ç«¯ç‚¹å°±ç»ª
        client.wait_for_endpoint(endpoint_info["endpoint_id"])
        
        # 4. æµ‹è¯•ç«¯ç‚¹
        client.test_endpoint(endpoint_info["endpoint_url"])
        
        print("ğŸ‰ éƒ¨ç½²å®Œæˆï¼")
        print(f"APIç«¯ç‚¹: {endpoint_info['endpoint_url']}")
        
    except Exception as e:
        print(f"âŒ éƒ¨ç½²å¤±è´¥: {e}")

if __name__ == "__main__":
    main() 
# Qwenæ¨¡å‹å¾®è°ƒå·¥å…·åŒ…

ä¸€ä¸ªåŠŸèƒ½å®Œæ•´ã€æ˜“äºä½¿ç”¨çš„Qwenæ¨¡å‹å¾®è°ƒå·¥å…·åŒ…ï¼Œæ”¯æŒå¤šç§å¾®è°ƒæ–¹å¼å’Œå†…å­˜ä¼˜åŒ–ç­–ç•¥ã€‚

## ğŸ“š ç›®å½•

- [ä¸»è¦ç‰¹æ€§](#-ä¸»è¦ç‰¹æ€§)
- [ç¯å¢ƒè¦æ±‚](#-ç¯å¢ƒè¦æ±‚)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
- [é…ç½®ç±»å‹å¯¹æ¯”](#-é…ç½®ç±»å‹å¯¹æ¯”)
- [è¯¦ç»†ä½¿ç”¨æ–¹æ³•](#-è¯¦ç»†ä½¿ç”¨æ–¹æ³•)
- [å†…å­˜ä¼˜åŒ–æŒ‡å—](#-å†…å­˜ä¼˜åŒ–æŒ‡å—)
- [é¡¹ç›®ç»“æ„](#-é¡¹ç›®ç»“æ„)
- [ä½¿ç”¨ç¤ºä¾‹](#-ä½¿ç”¨ç¤ºä¾‹)
- [æ–‡æ¡£ç´¢å¼•](#-æ–‡æ¡£ç´¢å¼•)
- [æ•…éšœæ’é™¤](#-æ•…éšœæ’é™¤)
- [æ€§èƒ½è°ƒä¼˜å»ºè®®](#-æ€§èƒ½è°ƒä¼˜å»ºè®®)
- [å¸¸è§é—®é¢˜å¿«é€Ÿè§£ç­”](#-å¸¸è§é—®é¢˜å¿«é€Ÿè§£ç­”)

## ğŸŒŸ ä¸»è¦ç‰¹æ€§

- **å¤šç§å¾®è°ƒæ–¹å¼**ï¼šæ”¯æŒå…¨å‚æ•°å¾®è°ƒã€LoRAã€QLoRAã€DeepSpeedåˆ†å¸ƒå¼è®­ç»ƒ
- **å†…å­˜ä¼˜åŒ–**ï¼šæä¾›4ç§ä¸åŒç¨‹åº¦çš„å†…å­˜ä¼˜åŒ–é…ç½®ï¼Œé€‚é…ä¸åŒGPU
- **è‡ªåŠ¨é…ç½®**ï¼šæ™ºèƒ½å‚æ•°éªŒè¯å’Œè‡ªåŠ¨DeepSpeedé…ç½®ç”Ÿæˆ
- **ç®€åŒ–ä½¿ç”¨**ï¼šä¸€é”®å¼è®­ç»ƒè„šæœ¬ï¼Œæ— éœ€å¤æ‚å‚æ•°è®¾ç½®
- **å®Œæ•´æ–‡æ¡£**ï¼šè¯¦ç»†çš„ä½¿ç”¨æŒ‡å—å’Œæ•…éšœæ’é™¤æ–‡æ¡£

## ğŸ“‹ ç¯å¢ƒè¦æ±‚

### åŸºç¡€è¦æ±‚
- Python 3.8+
- CUDA 11.0+
- 4GB+ GPUå†…å­˜ï¼ˆæœ€ä½é…ç½®ï¼‰

### æ¨èé…ç½®
- Python 3.9+
- CUDA 11.8+
- 8GB+ GPUå†…å­˜
- 16GB+ ç³»ç»Ÿå†…å­˜

### é‡è¦ç‰ˆæœ¬è¯´æ˜
- **transformers==4.51.3** (æ¨èï¼Œç»è¿‡æµ‹è¯•)
- **torch>=1.13.0** (æ”¯æŒCUDA 11.8+)
- **deepspeed>=0.9.0** (æ”¯æŒZeROä¼˜åŒ–)

### âš ï¸ é…ç½®å‚æ•°å…¼å®¹æ€§è¯´æ˜
åœ¨transformers 4.51.3ä¸­ï¼Œä¸ºäº†é¿å…`--load_best_model_at_end`å‚æ•°å†²çªï¼Œéœ€è¦**åŒæ—¶è®¾ç½®**ï¼š
- `evaluation_strategy`: æ ‡å‡†å‚æ•°å
- `eval_strategy`: å…¼å®¹æ€§å‚æ•°å

ä¸¤ä¸ªå‚æ•°çš„å€¼å¿…é¡»ä¸€è‡´ï¼Œéƒ½è®¾ç½®ä¸º`"steps"`æˆ–`"no"`ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements_stable.txt

# æˆ–è€…ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬
pip install -r requirements.txt
```

### 2. å‡†å¤‡æ•°æ®

å°†è®­ç»ƒæ•°æ®ä¿å­˜ä¸ºJSONLæ ¼å¼ï¼Œæ¯è¡ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
```json
{
  "instruction": "ä½ æ˜¯ä¸€ä¸ªç¾é£Ÿæ¨èå®˜ã€‚",
  "input": "ç”¨æˆ·çš„è¾“å…¥å†…å®¹",
  "output": "æœŸæœ›çš„è¾“å‡ºå†…å®¹"
}
```

### 3. é€‰æ‹©é…ç½®å¹¶å¼€å§‹è®­ç»ƒ

```bash
# ä½¿ç”¨é»˜è®¤LoRAé…ç½®
./run_train.sh

# ä½¿ç”¨å†…å­˜ä¼˜åŒ–é…ç½®ï¼ˆæ¨èï¼‰
./run_train.sh -t stage2_offload

# ä½¿ç”¨å…¶ä»–é…ç½®
./run_train.sh -t [é…ç½®ç±»å‹]
```

### 4. å®Œæ•´ç¤ºä¾‹ï¼ˆä»å®‰è£…åˆ°è®­ç»ƒï¼‰

```bash
# 1. å…‹éš†æˆ–ä¸‹è½½é¡¹ç›®
git clone <repository-url>
cd agent_data_collect

# 2. å®‰è£…ä¾èµ–
pip install -r requirements_stable.txt

# 3. æ£€æŸ¥GPUçŠ¶æ€
nvidia-smi

# 4. å¼€å§‹è®­ç»ƒï¼ˆæ¨èé…ç½®ï¼‰
./run_train.sh -t stage2_offload

# 5. è®­ç»ƒå®Œæˆåï¼ŒæŸ¥çœ‹ç»“æœ
ls -la output_qwen_deepspeed_stage2_offload/
```

## ğŸ“Š é…ç½®ç±»å‹å¯¹æ¯”

| é…ç½®ç±»å‹ | GPUå†…å­˜éœ€æ±‚ | è®­ç»ƒé€Ÿåº¦ | Batch Size | åºåˆ—é•¿åº¦ | é€‚ç”¨åœºæ™¯ |
|----------|-------------|----------|------------|----------|----------|
| `full` | >16GB | æœ€å¿« | 2 | 2048 | å…¨å‚æ•°å¾®è°ƒï¼Œæ•ˆæœæœ€å¥½ |
| `lora` | 6-12GB | å¿« | 2 | 2048 | å¹³è¡¡é€‰æ‹©ï¼Œæ¨èæ—¥å¸¸ä½¿ç”¨ |
| `qlora` | 4-8GB | ä¸­ç­‰ | 2 | 2048 | é‡åŒ–å¾®è°ƒï¼ŒèŠ‚çœå†…å­˜ |
| `deepspeed` | 8-16GB | å¿« | 4 | 2048 | å¤šGPUåˆ†å¸ƒå¼è®­ç»ƒ |
| `stage2_offload` | 6-12GB | ä¸­å¿« | 3 | 1792 | **æ¨è**ï¼Œå¹³è¡¡å†…å­˜å’Œæ€§èƒ½ |
| `stage3` | 4-6GB | ä¸­æ…¢ | 2 | 1536 | æœ€å¤§å†…å­˜ä¼˜åŒ– |
| `minimal` | <4GB | æ…¢ | 1 | 1024 | ç´§æ€¥æƒ…å†µï¼Œæœ€å°å†…å­˜éœ€æ±‚ |

## ğŸ”§ è¯¦ç»†ä½¿ç”¨æ–¹æ³•

### è®­ç»ƒè„šæœ¬é€‰é¡¹

```bash
./run_train.sh [é€‰é¡¹]

é€‰é¡¹:
  -t, --type TYPE        é€‰æ‹©å¾®è°ƒç±»å‹
  -c, --config FILE      ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
  -h, --help            æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
```

### é…ç½®æ–‡ä»¶ç»“æ„

æ¯ä¸ªé…ç½®æ–‡ä»¶åŒ…å«ä»¥ä¸‹ä¸»è¦å‚æ•°ï¼š

```json
{
  "model_name_or_path": "Qwen/Qwen2.5-0.5B-Instruct",
  "data_path": "data/your_data.jsonl",
  "eval_data_path": "data/your_eval_data.jsonl",
  "output_dir": "./output_qwen",
  "per_device_train_batch_size": 4,
  "gradient_accumulation_steps": 4,
  "learning_rate": 1e-4,
  "num_train_epochs": 3,
  "evaluation_strategy": "steps",
  "eval_strategy": "steps",
  "save_strategy": "steps",
  "eval_steps": 500,
  "save_steps": 500,
  "use_deepspeed": true,
  "deepspeed_stage": 2,
  "use_lora": true,
  "lora_r": 64
}
```

### è‡ªå®šä¹‰é…ç½®

1. å¤åˆ¶ç°æœ‰é…ç½®æ–‡ä»¶ï¼š
```bash
cp configs/train_config_lora.json configs/my_config.json
```

2. ä¿®æ”¹é…ç½®å‚æ•°

3. ä½¿ç”¨è‡ªå®šä¹‰é…ç½®ï¼š
```bash
./run_train.sh -c configs/my_config.json
```

## ğŸ’¾ å†…å­˜ä¼˜åŒ–æŒ‡å—

### é‡åˆ°CUDA OOMé”™è¯¯ï¼Ÿ

æŒ‰ä»¥ä¸‹é¡ºåºå°è¯•ï¼š

1. **é¦–é€‰æ–¹æ¡ˆ**ï¼šä½¿ç”¨å¹³è¡¡é…ç½®
```bash
./run_train.sh -t stage2_offload
```

2. **å†…å­˜ç´§å¼ **ï¼šä½¿ç”¨æœ€å¤§ä¼˜åŒ–
```bash
./run_train.sh -t stage3
```

3. **æç«¯æƒ…å†µ**ï¼šä½¿ç”¨æœ€å°é…ç½®
```bash
./run_train.sh -t minimal
```

### å†…å­˜ä¼˜åŒ–æŠ€å·§

```bash
# æ¸…ç†GPUç¼“å­˜
python -c "import torch; torch.cuda.empty_cache()"

# ç›‘æ§GPUä½¿ç”¨
watch -n 1 nvidia-smi

# æ£€æŸ¥è¿›ç¨‹å ç”¨
nvidia-smi pmon
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
agent_data_collect/
â”œâ”€â”€ configs/                    # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ train_config_lora.json           # LoRAé…ç½®
â”‚   â”œâ”€â”€ train_config_deepspeed.json      # DeepSpeedé…ç½®
â”‚   â”œâ”€â”€ train_config_deepspeed_stage2_offload.json  # æ¨èé…ç½®
â”‚   â”œâ”€â”€ train_config_deepspeed_stage3.json          # æœ€å¤§å†…å­˜ä¼˜åŒ–
â”‚   â””â”€â”€ train_config_deepspeed_minimal.json         # æœ€å°å†…å­˜é…ç½®
â”œâ”€â”€ data/                       # æ•°æ®æ–‡ä»¶ç›®å½•
â”œâ”€â”€ fine_tune_qwen.py          # ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ run_train.sh               # è®­ç»ƒå¯åŠ¨è„šæœ¬
â”œâ”€â”€ gradio_inference.py        # æ¨¡å‹æ¨ç†ç•Œé¢
â”œâ”€â”€ requirements_stable.txt    # ç¨³å®šç‰ˆä¾èµ–
â”œâ”€â”€ requirements.txt           # æœ€æ–°ç‰ˆä¾èµ–
â”œâ”€â”€ MEMORY_OPTIMIZATION_GUIDE.md  # å†…å­˜ä¼˜åŒ–è¯¦ç»†æŒ‡å—
â””â”€â”€ README_*.md                # å„ç§ä¸“é¡¹æ–‡æ¡£
```

## ğŸ¯ ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€è®­ç»ƒ

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®
./run_train.sh

# ä½¿ç”¨QLoRAèŠ‚çœå†…å­˜
./run_train.sh -t qlora

# ä½¿ç”¨æ¨èçš„å†…å­˜ä¼˜åŒ–é…ç½®
./run_train.sh -t stage2_offload
```

### é«˜çº§è®­ç»ƒ

```bash
# å¤šGPUè®­ç»ƒ
./run_train.sh -t deepspeed

# æé™å†…å­˜ä¼˜åŒ–
./run_train.sh -t minimal

# è‡ªå®šä¹‰é…ç½®
./run_train.sh -c configs/my_custom_config.json
```

### æ¨¡å‹æ¨ç†

```bash
# å¯åŠ¨Gradioç•Œé¢
python gradio_inference.py

# æˆ–ä½¿ç”¨è„šæœ¬
./run_gradio.sh
```

### è®­ç»ƒè¾“å‡ºç»“æ„

è®­ç»ƒå®Œæˆåï¼Œè¾“å‡ºç›®å½•åŒ…å«ä»¥ä¸‹æ–‡ä»¶ï¼š

```
output_qwen_*/
â”œâ”€â”€ adapter_config.json        # LoRAé…ç½®æ–‡ä»¶
â”œâ”€â”€ adapter_model.bin          # LoRAé€‚é…å™¨æƒé‡
â”œâ”€â”€ config.json               # æ¨¡å‹é…ç½®
â”œâ”€â”€ tokenizer_config.json     # åˆ†è¯å™¨é…ç½®
â”œâ”€â”€ tokenizer.json            # åˆ†è¯å™¨æ–‡ä»¶
â”œâ”€â”€ special_tokens_map.json   # ç‰¹æ®Štokenæ˜ å°„
â”œâ”€â”€ runs/                     # TensorBoardæ—¥å¿—
â”œâ”€â”€ checkpoint-*/             # è®­ç»ƒæ£€æŸ¥ç‚¹
â””â”€â”€ trainer_state.json        # è®­ç»ƒçŠ¶æ€
```

## ğŸ“– æ–‡æ¡£ç´¢å¼•

| æ–‡æ¡£ | æè¿° |
|------|------|
| [README_FINETUNE.md](README_FINETUNE.md) | å¾®è°ƒè¯¦ç»†æŒ‡å— |
| [README_INFERENCE.md](README_INFERENCE.md) | æ¨ç†ä½¿ç”¨è¯´æ˜ |
| [README_GRADIO.md](README_GRADIO.md) | Gradioç•Œé¢ä½¿ç”¨ |
| [README_LORA.md](README_LORA.md) | LoRAå¾®è°ƒä¸“é¡¹ |
| [README_ISSUE.md](README_ISSUE.md) | å¸¸è§é—®é¢˜è§£å†³ |
| [MEMORY_OPTIMIZATION_GUIDE.md](MEMORY_OPTIMIZATION_GUIDE.md) | å†…å­˜ä¼˜åŒ–å®Œæ•´æŒ‡å— |
| [ACCELERATE_VS_DEEPSPEED.md](ACCELERATE_VS_DEEPSPEED.md) | Accelerate vs DeepSpeedè¯¦ç»†å¯¹æ¯” |
| [TRAINING_COMPARISON_SUMMARY.md](TRAINING_COMPARISON_SUMMARY.md) | è®­ç»ƒæ–¹å¼å¿«é€Ÿå¯¹æ¯” |
| [EVAL_README.md](EVAL_README.md) | æ¨¡å‹è¯„ä¼°æŒ‡å— |

## ğŸ”¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDA OOMé”™è¯¯**
   - å‚è€ƒ [å†…å­˜ä¼˜åŒ–æŒ‡å—](MEMORY_OPTIMIZATION_GUIDE.md)
   - å°è¯•æ›´å°çš„batch_sizeæˆ–æ›´é«˜çš„DeepSpeed stage

2. **transformersç‰ˆæœ¬é—®é¢˜**
   - ä½¿ç”¨å›ºå®šç‰ˆæœ¬ï¼š`pip install transformers==4.51.3`

3. **DeepSpeedå®‰è£…é—®é¢˜**
   - é‡æ–°å®‰è£…ï¼š`pip install deepspeed --force-reinstall`

4. **é…ç½®æ–‡ä»¶é”™è¯¯**
   - æ£€æŸ¥JSONæ ¼å¼æ˜¯å¦æ­£ç¡®
   - ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨
   - âš ï¸ **é‡è¦**: éœ€è¦åŒæ—¶è®¾ç½®`evaluation_strategy`å’Œ`eval_strategy`
   - ç¡®ä¿è¯„ä¼°ç­–ç•¥å’Œä¿å­˜ç­–ç•¥åŒ¹é…

### è·å–å¸®åŠ©

```bash
# æŸ¥çœ‹è„šæœ¬å¸®åŠ©
./run_train.sh -h

# æ£€æŸ¥GPUçŠ¶æ€
nvidia-smi

# éªŒè¯é…ç½®æ–‡ä»¶
python3 validate_configs.py

# æˆ–è€…å•ç‹¬éªŒè¯æŸä¸ªé…ç½®æ–‡ä»¶
python3 -c "import json; print(json.load(open('configs/train_config_lora.json')))"

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
tail -f output_qwen/logs/train.log
```

## ğŸ“ˆ æ€§èƒ½è°ƒä¼˜å»ºè®®

### è®­ç»ƒæ•ˆç‡ä¼˜åŒ–

1. **ä½¿ç”¨åˆé€‚çš„batch size**
   - å•GPUï¼š2-8
   - å¤šGPUï¼šæ ¹æ®GPUæ•°é‡è°ƒæ•´

2. **æ¢¯åº¦ç´¯ç§¯**
   - å°batch sizeæ—¶å¢åŠ gradient_accumulation_steps
   - ä¿æŒæœ‰æ•ˆbatch size = batch_size Ã— accumulation_steps

3. **å­¦ä¹ ç‡è°ƒæ•´**
   - LoRAï¼š1e-4 ~ 5e-4
   - å…¨å‚æ•°ï¼š1e-5 ~ 5e-5

### å†…å­˜ä½¿ç”¨ä¼˜åŒ–

1. **åºåˆ—é•¿åº¦**
   - æ ¹æ®æ•°æ®åˆ†å¸ƒè°ƒæ•´max_seq_length
   - è¿‡é•¿çš„åºåˆ—ä¼šå¤§å¹…å¢åŠ å†…å­˜ä½¿ç”¨

2. **æ¨¡å‹é€‰æ‹©**
   - 0.5Bæ¨¡å‹ï¼šé€‚åˆå¿«é€Ÿå®éªŒ
   - 1.8Bæ¨¡å‹ï¼šæ›´å¥½æ•ˆæœä½†éœ€è¦æ›´å¤šå†…å­˜

## â“ å¸¸è§é—®é¢˜å¿«é€Ÿè§£ç­”

### Q: é‡åˆ°CUDA OOMé”™è¯¯æ€ä¹ˆåŠï¼Ÿ
**A:** æŒ‰é¡ºåºå°è¯•ï¼š`stage2_offload` â†’ `stage3` â†’ `minimal`

### Q: è®­ç»ƒé€Ÿåº¦å¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ
**A:** æ£€æŸ¥GPUåˆ©ç”¨ç‡ï¼Œå¢åŠ batch_sizeæˆ–å‡å°‘åºåˆ—é•¿åº¦

### Q: é…ç½®æ–‡ä»¶æŠ¥é”™æ€ä¹ˆåŠï¼Ÿ
**A:** ç¡®ä¿åŒæ—¶è®¾ç½®`evaluation_strategy`å’Œ`eval_strategy`ï¼Œä¸¤è€…å€¼è¦ä¸€è‡´

### Q: å¦‚ä½•é€‰æ‹©åˆé€‚çš„é…ç½®ï¼Ÿ
**A:** æ ¹æ®GPUå†…å­˜ï¼š>12GBç”¨`deepspeed`ï¼Œ6-12GBç”¨`stage2_offload`ï¼Œ<6GBç”¨`stage3`

### Q: Accelerateå’ŒDeepSpeedæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ
**A:** Accelerateç®€å•ç¨³å®šé€‚åˆæ–°æ‰‹ï¼ŒDeepSpeedå†…å­˜ä¼˜åŒ–å¼ºå¤§é€‚åˆç”Ÿäº§ç¯å¢ƒ

### Q: è®­ç»ƒç»“æœåœ¨å“ªé‡Œï¼Ÿ
**A:** åœ¨`output_qwen_*/`ç›®å½•ä¸‹ï¼ŒLoRAé€‚é…å™¨æ˜¯`adapter_model.bin`

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

1. Forké¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. æ¨é€åˆ°åˆ†æ”¯
5. åˆ›å»ºPull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ™ è‡´è°¢

- [Qwenå›¢é˜Ÿ](https://github.com/QwenLM/Qwen) æä¾›ä¼˜ç§€çš„åŸºç¡€æ¨¡å‹
- [Hugging Face](https://huggingface.co/) æä¾›transformersåº“
- [Microsoft DeepSpeed](https://github.com/microsoft/DeepSpeed) æä¾›åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ
- [PEFT](https://github.com/huggingface/peft) æä¾›å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- æäº¤Issue
- é‚®ä»¶è”ç³»
- æˆ–åœ¨é¡¹ç›®ä¸­ç•™è¨€

## ğŸš€ å¿«é€Ÿå‚è€ƒ

### å¸¸ç”¨å‘½ä»¤

```bash
# æ£€æŸ¥ç¯å¢ƒ
nvidia-smi
python3 -c "import torch; print(torch.cuda.is_available())"

# è®­ç»ƒå‘½ä»¤
./run_train.sh -t stage2_offload    # æ¨èé…ç½®
./run_train.sh -t stage3            # æœ€å¤§å†…å­˜ä¼˜åŒ–
./run_train.sh -t minimal           # æé™å†…å­˜é…ç½®

# éªŒè¯é…ç½®
python3 -c "import json; json.load(open('configs/train_config_lora.json'))"

# ç›‘æ§è®­ç»ƒ
watch -n 1 nvidia-smi
tail -f output_qwen_*/logs/train.log
```

### é…ç½®æ–‡ä»¶å¿«é€Ÿé€‰æ‹©

```bash
# æ ¹æ®GPUå†…å­˜é€‰æ‹©
>12GB  â†’ deepspeed
6-12GB â†’ stage2_offload  (æ¨è)
4-6GB  â†’ stage3
<4GB   â†’ minimal
```

## ğŸ“ æ›´æ–°è®°å½•

- **æœ€æ–°ç‰ˆæœ¬**: æ·»åŠ å¤šç§å†…å­˜ä¼˜åŒ–é…ç½®
- **ä¸»è¦æ”¹è¿›**: æ”¯æŒDeepSpeed ZeROä¼˜åŒ–
- **é…ç½®ä¿®å¤**: ä¿®å¤evaluation_strategyå‚æ•°å†²çª
- **æ–‡æ¡£å®Œå–„**: æä¾›å®Œæ•´çš„ä½¿ç”¨æŒ‡å—å’Œæ•…éšœæ’é™¤

---

â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ªStarï¼ 
#!/usr/bin/env python3
"""
è¯Šæ–­å’Œä¿®å¤æ¨¡å‹ç¼“å­˜é—®é¢˜
"""

import os
import shutil
import json
from pathlib import Path

def check_model_cache():
    """æ£€æŸ¥æ¨¡å‹ç¼“å­˜çŠ¶æ€"""
    print("ğŸ” æ£€æŸ¥æ¨¡å‹ç¼“å­˜çŠ¶æ€...")
    
    cache_dirs = [
        "./models",
        "~/.cache/huggingface",
        "/root/.cache/huggingface"
    ]
    
    for cache_dir in cache_dirs:
        expanded_dir = os.path.expanduser(cache_dir)
        if os.path.exists(expanded_dir):
            print(f"ğŸ“ å‘ç°ç¼“å­˜ç›®å½•: {expanded_dir}")
            
            # æ£€æŸ¥Qwenæ¨¡å‹
            for item in os.listdir(expanded_dir):
                if "qwen" in item.lower() or "Qwen" in item:
                    model_dir = os.path.join(expanded_dir, item)
                    print(f"   ğŸ” æ£€æŸ¥æ¨¡å‹: {model_dir}")
                    
                    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
                    required_files = [
                        "config.json",
                        "tokenizer.json",
                        "tokenizer_config.json"
                    ]
                    
                    missing_files = []
                    for file in required_files:
                        file_path = os.path.join(model_dir, file)
                        if os.path.exists(file_path):
                            try:
                                if file.endswith('.json'):
                                    with open(file_path, 'r') as f:
                                        json.load(f)
                                print(f"      âœ… {file}")
                            except Exception as e:
                                print(f"      âŒ {file} (æŸå: {e})")
                                missing_files.append(file)
                        else:
                            print(f"      âŒ {file} (ç¼ºå¤±)")
                            missing_files.append(file)
                    
                    if missing_files:
                        print(f"      âš ï¸  æ¨¡å‹ä¸å®Œæ•´ï¼Œç¼ºå¤±: {missing_files}")
                        return False, model_dir
                    else:
                        print(f"      âœ… æ¨¡å‹å®Œæ•´")
                        return True, model_dir
        else:
            print(f"ğŸ“ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨: {expanded_dir}")
    
    return False, None

def clean_cache():
    """æ¸…ç†æŸåçš„æ¨¡å‹ç¼“å­˜"""
    print("ğŸ§¹ æ¸…ç†æ¨¡å‹ç¼“å­˜...")
    
    cache_dirs = [
        "./models",
        "~/.cache/huggingface/hub",
        "/root/.cache/huggingface/hub"
    ]
    
    for cache_dir in cache_dirs:
        expanded_dir = os.path.expanduser(cache_dir)
        if os.path.exists(expanded_dir):
            try:
                print(f"ğŸ—‘ï¸  æ¸…ç†: {expanded_dir}")
                
                # åªåˆ é™¤Qwenç›¸å…³çš„æ¨¡å‹
                for item in os.listdir(expanded_dir):
                    if "qwen" in item.lower():
                        item_path = os.path.join(expanded_dir, item)
                        if os.path.isdir(item_path):
                            shutil.rmtree(item_path)
                            print(f"   âœ… å·²åˆ é™¤: {item}")
                        else:
                            os.remove(item_path)
                            print(f"   âœ… å·²åˆ é™¤: {item}")
                
            except Exception as e:
                print(f"   âŒ æ¸…ç†å¤±è´¥: {e}")

def download_model_with_modelscope():
    """ä½¿ç”¨ModelScopeä¸‹è½½æ¨¡å‹"""
    print("ğŸ“¥ å°è¯•ä½¿ç”¨ModelScopeä¸‹è½½æ¨¡å‹...")
    
    try:
        from modelscope import snapshot_download
        
        model_name = "qwen/Qwen2.5-0.5B-Instruct"
        cache_dir = "./models"
        
        print(f"ä¸‹è½½æ¨¡å‹: {model_name}")
        print(f"ä¿å­˜åˆ°: {cache_dir}")
        
        model_dir = snapshot_download(model_name, cache_dir=cache_dir)
        print(f"âœ… ä¸‹è½½æˆåŠŸ: {model_dir}")
        return model_dir
        
    except ImportError:
        print("âŒ ModelScopeæœªå®‰è£…")
        return None
    except Exception as e:
        print(f"âŒ ModelScopeä¸‹è½½å¤±è´¥: {e}")
        return None

def main():
    print("ğŸ› ï¸  æ¨¡å‹ç¼“å­˜ä¿®å¤å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥ç°æœ‰ç¼“å­˜
    is_valid, model_path = check_model_cache()
    
    if is_valid:
        print(f"\nâœ… æ¨¡å‹ç¼“å­˜å®Œæ•´: {model_path}")
        print("å¯ä»¥ç›´æ¥ä½¿ç”¨ç°æœ‰æ¨¡å‹è¿›è¡Œè®­ç»ƒ")
        return model_path
    
    print(f"\nâŒ æ¨¡å‹ç¼“å­˜ä¸å®Œæ•´æˆ–æŸå")
    
    # è¯¢é—®æ˜¯å¦æ¸…ç†
    response = input("\næ˜¯å¦æ¸…ç†æŸåçš„ç¼“å­˜å¹¶é‡æ–°ä¸‹è½½? (y/N): ").strip().lower()
    
    if response in ['y', 'yes']:
        # æ¸…ç†ç¼“å­˜
        clean_cache()
        
        # å°è¯•é‡æ–°ä¸‹è½½
        model_dir = download_model_with_modelscope()
        
        if model_dir:
            print(f"\nğŸ‰ æ¨¡å‹ä¿®å¤æˆåŠŸ!")
            print(f"æ¨¡å‹ä½ç½®: {model_dir}")
            print("\nç°åœ¨å¯ä»¥è¿è¡Œè®­ç»ƒ:")
            print("python fine_tune_qwen.py --config_file configs/train_config_full.json")
            return model_dir
        else:
            print(f"\nâŒ è‡ªåŠ¨ä¸‹è½½å¤±è´¥")
            print("è¯·æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹:")
            print("1. ./download_model.sh")
            print("2. æˆ–ä½¿ç”¨å…¶ä»–ä¸‹è½½æ–¹å¼")
            return None
    else:
        print("\nè·³è¿‡æ¸…ç†ï¼Œè¯·æ‰‹åŠ¨å¤„ç†æ¨¡å‹ç¼“å­˜é—®é¢˜")
        return None

if __name__ == "__main__":
    main() 